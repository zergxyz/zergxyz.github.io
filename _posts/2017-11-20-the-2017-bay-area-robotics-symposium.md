---
layout:    post
title:     "The 2017 Bay Area Robotics Symposium"
date:      2017-11-20 20:00:00
permalink: /2017/11/20/the-2017-bay-area-robotics-symposium/
---

Last Friday, I participated in the [Bay Area Robotics Symposium][2] for the
first time. Since 2013, this has been an annual November event with alternating
hosts of the University of California, Berkeley, and Stanford University. This
year, it was held in Berkeley, and since by now I am closer to calling myself a
robotics researcher, and [additionally have (finally!) a robotics-related
preprint online][1], I really had no excuse not to join this time around.

<p style="text-align:center;"> 
<img src="{{site.url}}/assets/BARS/auditorium.JPG" alt="bars">
<i>
The International House auditorium, where BARS took place.
</i>
</p>

BARS took place at the International House in the southeast corner of the UC
Berkeley campus. The talks were in the room shown in the picture above. As
usual:

- I arrived early.
- I sat near the front of the room. Thus, this picture shows basically the
  entirety of the auditorium.

I normally follow the two rules above because of the need to (a) meet my sign
language interpreters early, and (b) grab a seat by the front to get a good view
of them. Sadly, it means that (as usual) I don't get other students to sit next
to me. In fact, the seats nearby me were empty. One of these days, I will figure
out how to sit next to other students.

After about a 15 minute delay (typical Berkeley), BARS finally got started. The
Berkeley host, Professor Anca Dragan, gave a few opening remarks, which included
that BARS 2017 had (if I recall correctly) 392 people signed up. The capacity
was 500, I think, and I'm actually surprised that we didn't hit the limit.
Perhaps CoRL 2017, held recently, meant that BARS 2017 was redundant?

Anyway, soon we started off with the agenda. We started with the first of four
sets of faculty talks, each consisting of six faculty giving ten minute talks.
Berkeley Professor Pieter Abbeel started things off.

<p style="text-align:center;"> 
<img src="{{site.url}}/assets/BARS/abbeel.JPG" alt="bars">
<i>
Pieter Abbeel started off the faculty talks. He presented "Deep Learning for
Robotics". Apologies for the glare on the camera --- I am a rookie with using my
iPhone for cameras. You can also see my sign language interpreter there, who had
her work cut out for her due to Abbeel's fast and energetic speaking rate.
</i>
</p>

My goodness, how does he get all these papers?!? His talk started off by listing
his *long* list of publications ... in 2017 alone. Then he talked about
Meta-Learning, which is what he's most interested in nowadays within AI. (Just
to be clear, I said "most interested," not "the only thing he's interested in.")
Incidentally, Abbeel was [featured in the New York Times for co-founding
Embodied Intelligence][3]. I'm excited to see what they will produce.

We then had more faculty talks. Once these concluded, we moved on to the first
of two **student spotlight talk sessions**, when students gave 1-minute
lightning talks on their research. As expected, about 90% of the students went
over their alloted time, and most wasted time by saying "My name is X and I'm a
student at Y advised by Z and blah blah blah." The good news is that many of the
presentations were interesting enough to pique the curiosity of a nontrivial
fraction of the audience. Then those folks can read the students' papers in
their own time.

I didn't give a lightning talk. I'm not sure why, but I suppose professors could
only pick two or three of their students due to time constraints.

We then had our first coffee break. Yay! I stood up, stretched, and briefly
chatted with a few other people from Berkeley who I knew. I wish I had talked to
some students from Stanford, though. How do people network to brand-new folks at
events like these? I really wish I knew the answer.

After another set of faculty talks (including Ken Goldberg's work on the
Dexterity-Network), and then a lunch break, we had ... our keynote talk.

<p style="text-align:center;"> 
<img src="{{site.url}}/assets/BARS/grand_challenge.JPG" alt="bars">
<i>
Professor Robert Full at the end of his keynote talk, asking the audience about
our thoughts on a suitable "Grand Challenge" for robotics.
</i>
</p>

Professor Full isn't technically a core robotics faculty --- I think --- because
"biomechanics" is a better way of describing his work. But he quickly captivated
the audience with his funny videos on insects and squirrels going through wild
motions ... and then videos of robots attempting to replicate that movement. I
particularly liked the videos of insects and robots that were able to resist
insane amounts of forces and squeeze their way through impossibly tiny paths.
Judging from the frequent audience laughter, I wasn't the only one who enjoyed
his talk.

Towards the end, Professor Full asked us for "Grand Challenges" of Robotics. One
of the professors who I work with, Ken Goldberg, offered "the ability of a robot
to pick up anything a human can pick up, including stuff that doesn't want to be
picked up." You can verify this by [looking at his Twitter][4]. I agree with
him.

Ken, meanwhile, helped me out a bit later that day. During the second coffee
break, Ken gathered a few of his students (including me) and introduced us to
Stanford Professor Allison Okamura, who's also done some work on surgical
robotics. At least I got to network *a bit*, which is better than the usual
nothing!

We then had our second set of lightning talks, with the same old issues (people
going over their time, etc.), and then our fourth set of faculty talks. This
featured stars such as Jitendra Malik and Sergey Levine.  I enjoyed Malik's
talk, which was entertaining for two reasons. First, he joked that vision and
robotics people (and Malik is a vision person) were historically separate
communities in AI, but after drastic improvements in image recognition due to
Deep Learning, the "robotics people better pay attention to what the vision
people are doing." 

The second joke Malik made was with regards to Stanford vs Berkley. The joke was
that Stanford people could develop algorithms for robots (e.g., navigation) that
perform well when applied to Stanford-based environments, but which fail on
Berkeley-based environments.  Why? Stanford is nice and clean, Berkeley is dirty
and messy.

Well, UC Berkeley may be a bit run down, not to mention crowded (see image
below), but it's the people that matter, right?

<p style="text-align:center;"> 
<img src="{{site.url}}/assets/BARS/cramped.JPG" alt="bars">
<i>
Yeowch. BARS sure was popular! Well, that, and the venue is a bit too small for
what we're offering. No wonder I regularly hear complaints that Berkeley is too
crowded.
</i>
</p>

Some random, concluding thoughts:

- Two areas of research in robotics (and AI more generally) that are hugely
  popular are *safety* and *robustness*. These are related, though there are
  subtle differences.

- There were several faculty talking about aerospace dynamics and mechanical
  engineering. This is not my area of research so I had a hard time processing
  the concepts. There was also more on surgical robotics than I expected, due to
  several Stanford faculty (as our surgical robotics person, Ken, is mostly
  working on grasping). Berkeley, naturally, has more faculty who do Deep
  Reinforcement Learning for Robotics, and I find that to be the most
  riveting field of robotics and AI.

- Many faculty kept saying some variant of: "we'll do Deep Learning because it's
  so popular and works." Yes, I know it's popular, and it's funny to talk about
  it, but by now this has grown stale on me and I wish people would cut back on
  their hackneyed Deep Learning comments.

- Unfortunately, since I spent most of the coffee breaks talking to a few people
  or relaxing, I didn't get to attend either poster session. I got a glimpse of
  one of them and it looked crowded (and noisy) so maybe I didn't miss much.

Well, that's a wrap. I look forward to attending BARS 2018 at Stanford. Thank
you to everyone who helped make BARS 2017 happen!

[1]:https://arxiv.org/abs/1709.06668
[2]:http://interact.berkeley.edu/BARS2017/index.html
[3]:https://www.nytimes.com/2017/11/06/technology/artificial-intelligence-start-up.html
[4]:https://twitter.com/ken_goldberg/status/931646946804080640
